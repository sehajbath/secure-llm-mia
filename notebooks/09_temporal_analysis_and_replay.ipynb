{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8ee2811c",
      "metadata": {},
      "source": [
        "# 09 \u00b7 Temporal Analysis & Replay\n",
        "\n",
        "Assess cross-slice generalization and replay effects using attack outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0cfdc95",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Persistent Drive + run mode setup\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    DRIVE_MOUNT = Path('/content/drive')\n",
        "    if not DRIVE_MOUNT.exists():\n",
        "        drive.mount('/content/drive')\n",
        "except Exception as exc:  # pragma: no cover\n",
        "    print(f'Colab drive mount skipped: {exc}')\n",
        "\n",
        "if Path('/content/drive').exists():\n",
        "    DRIVE_ROOT = Path('/content/drive/MyDrive').resolve()\n",
        "else:\n",
        "    DRIVE_ROOT = Path.home().resolve()\n",
        "\n",
        "PROJECT_ROOT = DRIVE_ROOT / 'secure-llm-mia'\n",
        "if not PROJECT_ROOT.exists():\n",
        "    raise FileNotFoundError('Run 00_colab_setup.ipynb first to clone the repo on Drive.')\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "os.environ['SECURE_LLM_MIA_ROOT'] = str(PROJECT_ROOT)\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "from src.utils.runtime import current_run_mode\n",
        "\n",
        "RUN_MODE = current_run_mode()\n",
        "print('PROJECT_ROOT:', PROJECT_ROOT)\n",
        "print('Active run mode:', RUN_MODE.name, '-', RUN_MODE.description)\n",
        "\n",
        "DATA_ROOT = PROJECT_ROOT / 'data'\n",
        "ARTIFACTS_DIR = PROJECT_ROOT / 'artifacts'\n",
        "CHECKPOINT_ROOT = PROJECT_ROOT / 'checkpoints'\n",
        "for path in (DATA_ROOT, ARTIFACTS_DIR, CHECKPOINT_ROOT):\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "BHC_DATA_DIR = DRIVE_ROOT / 'mimic-iv-bhc'\n",
        "BHC_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "BHC_CSV_PATH = BHC_DATA_DIR / 'mimic-iv-bhc.csv'\n",
        "print('BHC CSV path:', BHC_CSV_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150dacb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "REPORTS_DIR = PROJECT_ROOT / 'reports'\n",
        "FIGS_DIR = REPORTS_DIR / 'figs'\n",
        "TABLES_DIR = REPORTS_DIR / 'tables'\n",
        "FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "metrics_path = REPORTS_DIR / f'metrics_core_{RUN_MODE.name}.csv'\n",
        "if not metrics_path.exists():\n",
        "    raise FileNotFoundError('Core metrics missing. Run notebook 06 first to populate metrics_core_*.csv files.')\n",
        "\n",
        "metrics_df = pd.read_csv(metrics_path)\n",
        "if metrics_df.empty:\n",
        "    raise ValueError('Metrics dataframe is empty. Ensure notebook 06 finished successfully.')\n",
        "\n",
        "metrics_df = metrics_df.sort_values(['track', 'slice_id'])\n",
        "print('Loaded metrics rows:', len(metrics_df))\n",
        "tracks = metrics_df['track'].unique().tolist()\n",
        "print('Replay tracks detected:', tracks)\n",
        "\n",
        "auc_pivot = metrics_df.pivot(index='slice_id', columns='track', values='auc')\n",
        "tpr_pivot = metrics_df.pivot(index='slice_id', columns='track', values='tpr_at_0.01')\n",
        "\n",
        "auc_delta = auc_pivot.max(axis=1) - auc_pivot.min(axis=1)\n",
        "tpr_delta = tpr_pivot.max(axis=1) - tpr_pivot.min(axis=1)\n",
        "summary = pd.DataFrame({\n",
        "    'slice_id': auc_pivot.index,\n",
        "    **{f'auc_{track}': auc_pivot[track] for track in auc_pivot.columns},\n",
        "    **{f'tpr_{track}': tpr_pivot[track] for track in tpr_pivot.columns},\n",
        "    'auc_delta': auc_delta,\n",
        "    'tpr_delta': tpr_delta,\n",
        "}).sort_values('slice_id')\n",
        "\n",
        "summary_path = TABLES_DIR / f'temporal_summary_{RUN_MODE.name}.csv'\n",
        "summary.to_csv(summary_path, index=False)\n",
        "print(f'Saved temporal summary table to {summary_path}')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "for track in tracks:\n",
        "    subset = metrics_df[metrics_df['track'] == track]\n",
        "    ax.plot(subset['slice_id'], subset['auc'], marker='o', label=track)\n",
        "ax.set_xlabel('Slice ID')\n",
        "ax.set_ylabel('AUC')\n",
        "ax.set_title('Temporal AUC by Replay Track')\n",
        "ax.grid(True, linestyle='--', alpha=0.4)\n",
        "ax.legend()\n",
        "auc_fig_path = FIGS_DIR / f'temporal_auc_{RUN_MODE.name}.png'\n",
        "fig.savefig(auc_fig_path, dpi=200, bbox_inches='tight')\n",
        "plt.close(fig)\n",
        "print(f'Saved AUC plot to {auc_fig_path}')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "for track in tracks:\n",
        "    subset = metrics_df[metrics_df['track'] == track]\n",
        "    ax.plot(subset['slice_id'], subset['tpr_at_0.01'], marker='o', label=track)\n",
        "ax.set_xlabel('Slice ID')\n",
        "ax.set_ylabel('TPR @ 1% FPR')\n",
        "ax.set_title('Temporal TPR@1%FPR by Replay Track')\n",
        "ax.grid(True, linestyle='--', alpha=0.4)\n",
        "ax.legend()\n",
        "tpr_fig_path = FIGS_DIR / f'temporal_tpr_{RUN_MODE.name}.png'\n",
        "fig.savefig(tpr_fig_path, dpi=200, bbox_inches='tight')\n",
        "plt.close(fig)\n",
        "print(f'Saved TPR plot to {tpr_fig_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85b920c",
      "metadata": {},
      "source": [
        "Temporal AUC/TPR summaries saved to `reports/tables` and plots written to `reports/figs`.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": ""
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}