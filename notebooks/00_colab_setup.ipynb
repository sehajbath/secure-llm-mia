{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e64c1080",
      "metadata": {
        "id": "e64c1080"
      },
      "source": [
        "# 00 · Colab Setup\n",
        "\n",
        "Set up dependencies, authentication, and guardrails before running downstream notebooks.\n",
        "\n",
        "> **Data Protection:** Access to MIMIC datasets requires PhysioNet credentials and human oversight. Never sync PHI to this repo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18196c71",
      "metadata": {
        "id": "18196c71"
      },
      "source": [
        "## Guardrails\n",
        "- Use this Colab only within approved clinical research scopes.\n",
        "- Mount Google Drive with restricted sharing.\n",
        "- Update configuration flags to disable exporting raw text artifacts.\n",
        "- Double-check that only anonymized metrics leave the runtime."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sehajbath/secure-llm-mia.git\n",
        "%cd secure-llm-mia\n"
      ],
      "metadata": {
        "id": "uedL20iizZ3K",
        "outputId": "59287cd3-352c-4671-bdd7-1b96eb583e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uedL20iizZ3K",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'secure-llm-mia'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 84 (delta 7), reused 84 (delta 7), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (84/84), 36.74 KiB | 1.67 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n",
            "/content/secure-llm-mia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2ebcd504",
      "metadata": {
        "id": "2ebcd504",
        "outputId": "9bb1fe2c-6ad5-4ff0-f672-207105c7118d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project root: /content/secure-llm-mia\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(os.getcwd()).resolve()  # -> /content/secure-llm-mia\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cb5b28ac",
      "metadata": {
        "id": "cb5b28ac",
        "outputId": "8e1fb063-97a0-4212-ba09-b48d4549291f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies from the repo environment spec\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "requirements_path = PROJECT_ROOT / 'env' / 'requirements.txt'\n",
        "if requirements_path.exists():\n",
        "    print('Installing dependencies...')\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', '-r', str(requirements_path)], check=False)\n",
        "else:\n",
        "    print('requirements.txt not found. Verify repo checkout or adjust path.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "46406032",
      "metadata": {
        "id": "46406032",
        "outputId": "2fda1ab3-6bd6-44d0-e5b7-44873667acfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Hugging Face token (press ENTER to skip): ··········\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Hugging Face Hub (token input is not stored)\n",
        "from getpass import getpass\n",
        "try:\n",
        "    from huggingface_hub import login\n",
        "except Exception as exc:  # pragma: no cover\n",
        "    print(f'huggingface_hub not available: {exc}')\n",
        "else:\n",
        "    hf_token = getpass('Enter Hugging Face token (press ENTER to skip): ')\n",
        "    if hf_token:\n",
        "        login(token=hf_token, add_to_git_credential=True)\n",
        "    else:\n",
        "        print('Token not provided. Access to meta-llama/Llama-3.1-8B will fail if gated.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7d6c1fa5",
      "metadata": {
        "id": "7d6c1fa5",
        "outputId": "e0664e47-9252-4f0c-94ad-53b285f2e1d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W&B disabled by default. Set enable_wandb=True to log runs.\n"
          ]
        }
      ],
      "source": [
        "# Optional: initialize Weights & Biases logging\n",
        "try:\n",
        "    import wandb\n",
        "    enable_wandb = False  # TODO: flip to True after configuring wandb settings.\n",
        "    if enable_wandb:\n",
        "        wandb.login()\n",
        "        wandb.init(project='secure-llm-mia', config={'notebook': '00_colab_setup'})\n",
        "    else:\n",
        "        print('W&B disabled by default. Set enable_wandb=True to log runs.')\n",
        "except Exception as exc:  # pragma: no cover\n",
        "    print(f'wandb not available: {exc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bd342a60",
      "metadata": {
        "id": "bd342a60",
        "outputId": "7bfd37ce-f176-4361-806d-4a986f094897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive mounted at /content/drive.\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive if executing inside Colab\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    DRIVE_ROOT = Path('/content/drive')\n",
        "    if not DRIVE_ROOT.exists():\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "        print('Drive mounted at /content/drive.')\n",
        "    else:\n",
        "        print('Drive already mounted.')\n",
        "except ImportError:\n",
        "    print('Not running inside Google Colab; skipping Drive mount.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4f7d783b",
      "metadata": {
        "id": "4f7d783b",
        "outputId": "2960c427-861c-4019-a75a-76903580cc4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA not available. Colab may be on CPU-only instance.\n"
          ]
        }
      ],
      "source": [
        "# Determine runtime device capabilities\n",
        "import torch\n",
        "\n",
        "\n",
        "def describe_device() -> None:\n",
        "    if not torch.cuda.is_available():\n",
        "        print('CUDA not available. Colab may be on CPU-only instance.')\n",
        "        return\n",
        "    device = torch.cuda.get_device_name(0)\n",
        "    capability = torch.cuda.get_device_capability(0)\n",
        "    print(f'CUDA device: {device} (cc {capability})')\n",
        "    print(f'BF16 support: {torch.cuda.is_bf16_supported()}')\n",
        "    print(f'FP16 support: {torch.cuda.is_available()}')\n",
        "\n",
        "\n",
        "describe_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "90414433",
      "metadata": {
        "id": "90414433",
        "outputId": "ff85193e-aca7-4886-e5b6-138436adf24c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data cache directory: /content/secure-llm-mia/data_cache\n",
            "Artifact root: /content/secure-llm-mia/artifacts\n"
          ]
        }
      ],
      "source": [
        "# Configure deterministic seeds and 4-bit defaults\n",
        "from src.utils.seed import set_global_seed\n",
        "from src.constants import ensure_directories, DATA_CACHE_DIR, ARTIFACT_ROOT\n",
        "\n",
        "PROJECT_TEMP = PROJECT_ROOT / 'colab_temp'\n",
        "PROJECT_TEMP.mkdir(exist_ok=True)\n",
        "set_global_seed(17)\n",
        "ensure_directories()\n",
        "print(f'Data cache directory: {DATA_CACHE_DIR}')\n",
        "print(f'Artifact root: {ARTIFACT_ROOT}')\n",
        "os.environ['BITSANDBYTES_NOWELCOME'] = '1'  # ensures bnb does not print ASCII art"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca72ae3",
      "metadata": {
        "id": "6ca72ae3"
      },
      "source": [
        "✅ **Next steps:** Proceed to `01_data_intake_and_clean.ipynb`, update dataset paths, and run the synthetic smoke test before working with credentialed data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}