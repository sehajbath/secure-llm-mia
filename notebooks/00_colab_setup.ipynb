{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fabf67a7",
      "metadata": {
        "id": "fabf67a7"
      },
      "source": [
        "# 00 · Colab Setup\n",
        "\n",
        "Configure a persistent Drive-backed workspace for temporal fine-tuning and MIA experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18636e82",
      "metadata": {
        "id": "18636e82"
      },
      "source": [
        "## Guardrails\n",
        "- Use credentialed MIMIC data only on encrypted Drive folders.\n",
        "- Never sync PHI or credentials back to GitHub.\n",
        "- Enable config flags that disable raw-text exports before sharing artifacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4106b099",
      "metadata": {
        "id": "4106b099",
        "outputId": "8df5cda3-57d0-452b-9457-2c55e8239b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive root: /content/drive/MyDrive\n",
            "Project root: /content/drive/MyDrive/secure-llm-mia\n",
            "BHC data directory: /content/drive/MyDrive/mimic-iv-bhc\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive and declare persistent paths\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive')\n",
        "    DRIVE_ROOT = Path('/content/drive/MyDrive').resolve()\n",
        "except Exception as exc:  # pragma: no cover\n",
        "    print(f'Drive mount skipped or not on Colab: {exc}')\n",
        "    DRIVE_ROOT = Path.home().resolve()\n",
        "\n",
        "PROJECT_ROOT = DRIVE_ROOT / 'secure-llm-mia'\n",
        "BHC_DATA_DIR = DRIVE_ROOT / 'mimic-iv-bhc'\n",
        "BHC_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "os.environ['SECURE_LLM_MIA_ROOT'] = str(PROJECT_ROOT)\n",
        "print('Drive root:', DRIVE_ROOT)\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('BHC data directory:', BHC_DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33a4fb6e",
      "metadata": {
        "id": "33a4fb6e",
        "outputId": "bc106f42-1555-434d-e789-75c04b33215c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synced repository at /content/drive/MyDrive/secure-llm-mia\n"
          ]
        }
      ],
      "source": [
        "# Clone or update the GitHub repo on Drive\n",
        "import subprocess\n",
        "\n",
        "REPO_URL = 'https://github.com/sehajbath/secure-llm-mia.git'\n",
        "PROJECT_PARENT = PROJECT_ROOT.parent\n",
        "PROJECT_PARENT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "git_dir = PROJECT_ROOT / '.git'\n",
        "if not PROJECT_ROOT.exists():\n",
        "    subprocess.run(['git', 'clone', REPO_URL, str(PROJECT_ROOT)], check=True)\n",
        "elif not git_dir.exists():\n",
        "    raise RuntimeError(f'{PROJECT_ROOT} exists but is not a git repo. Clean up or move it before rerunning setup.')\n",
        "else:\n",
        "    subprocess.run(['git', '-C', str(PROJECT_ROOT), 'pull'], check=True)\n",
        "\n",
        "os.chdir(PROJECT_ROOT)\n",
        "print('Synced repository at', PROJECT_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ab89dba2",
      "metadata": {
        "id": "ab89dba2",
        "outputId": "7cfddc5b-45ad-4b97-c113-8a0bc993e450",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ /content/drive/MyDrive/secure-llm-mia/data\n",
            "✓ /content/drive/MyDrive/secure-llm-mia/artifacts\n",
            "✓ /content/drive/MyDrive/secure-llm-mia/checkpoints\n",
            "✓ /content/drive/MyDrive/mimic-iv-bhc\n"
          ]
        }
      ],
      "source": [
        "# Ensure persistent directories exist\n",
        "for path in [PROJECT_ROOT / 'data', PROJECT_ROOT / 'artifacts', PROJECT_ROOT / 'checkpoints']:\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "    print('✓', path)\n",
        "\n",
        "BHC_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print('✓', BHC_DATA_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9687e953",
      "metadata": {
        "id": "9687e953",
        "outputId": "01bd9381-5f68-447e-c009-802dbd3259eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SECURE_LLM_MIA_RUN_MODE = subset\n",
            "Quick debugging subset (<=2k rows) for lightweight Colab smoke tests.\n"
          ]
        }
      ],
      "source": [
        "# Display active run mode (subset vs full)\n",
        "from src.utils.runtime import current_run_mode\n",
        "\n",
        "RUN_MODE = current_run_mode()\n",
        "print('SECURE_LLM_MIA_RUN_MODE =', RUN_MODE.name)\n",
        "print(RUN_MODE.description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b60d4f",
      "metadata": {
        "id": "f4b60d4f"
      },
      "outputs": [],
      "source": [
        "# Install Python dependencies\n",
        "import subprocess\n",
        "\n",
        "requirements = PROJECT_ROOT / 'env' / 'requirements.txt'\n",
        "if requirements.exists():\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-U', '-r', str(requirements)], check=False)\n",
        "else:\n",
        "    print('requirements.txt missing; verify repo sync.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "546448b1",
      "metadata": {
        "id": "546448b1",
        "outputId": "b37a44d9-eff0-44cd-b1e1-64c1f1b9ce0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Hugging Face token (press ENTER to skip): ··········\n"
          ]
        }
      ],
      "source": [
        "# Authenticate with Hugging Face Hub if needed\n",
        "from getpass import getpass\n",
        "try:\n",
        "    from huggingface_hub import login\n",
        "except Exception as exc:  # pragma: no cover\n",
        "    print(f'huggingface_hub unavailable: {exc}')\n",
        "else:\n",
        "    token = getpass('Enter Hugging Face token (press ENTER to skip): ')\n",
        "    if token:\n",
        "        login(token=token, add_to_git_credential=True)\n",
        "    else:\n",
        "        print('Skipping HF login; gated models may be unavailable.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "60af5a75",
      "metadata": {
        "id": "60af5a75",
        "outputId": "bfc8a46c-6256-47f6-bc13-d14f8f4145e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights & Biases disabled. Set enable_wandb=True after configuring secrets.\n"
          ]
        }
      ],
      "source": [
        "# Optional: Weights & Biases logging\n",
        "try:\n",
        "    import wandb\n",
        "    enable_wandb = False\n",
        "    if enable_wandb:\n",
        "        wandb.login()\n",
        "        wandb.init(project='secure-llm-mia', config={'notebook': '00_colab_setup'})\n",
        "    else:\n",
        "        print('Weights & Biases disabled. Set enable_wandb=True after configuring secrets.')\n",
        "except Exception as exc:\n",
        "    print(f'wandb not available: {exc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "eab882d9",
      "metadata": {
        "id": "eab882d9",
        "outputId": "d2a472dc-ecb7-4469-9933-a51ee6229879",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA not available. Request a GPU runtime (A100/T4) for fine-tuning runs.\n"
          ]
        }
      ],
      "source": [
        "# Inspect GPU resources\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    capability = torch.cuda.get_device_capability(0)\n",
        "    print(f'CUDA device: {device_name} (cc {capability})')\n",
        "    print('BF16 support:', torch.cuda.is_bf16_supported())\n",
        "else:\n",
        "    print('CUDA not available. Request a GPU runtime (A100/T4) for fine-tuning runs.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "29913b32",
      "metadata": {
        "id": "29913b32",
        "outputId": "72c8dfd2-7d62-4d6e-ece0-e3c47ebf7afe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data cache: /content/drive/MyDrive/secure-llm-mia/data_cache\n",
            "Artifact root: /content/drive/MyDrive/secure-llm-mia/artifacts\n"
          ]
        }
      ],
      "source": [
        "# Initialize deterministic seeds\n",
        "from src.utils.seed import set_global_seed\n",
        "from src.constants import ensure_directories, DATA_CACHE_DIR, ARTIFACT_ROOT\n",
        "\n",
        "set_global_seed(17)\n",
        "ensure_directories()\n",
        "print('Data cache:', DATA_CACHE_DIR)\n",
        "print('Artifact root:', ARTIFACT_ROOT)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}